{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and build matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/archnnj/Development/recsys/recsys_polimi_challenge_2018/repo\n"
     ]
    }
   ],
   "source": [
    "cd ../../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline\n",
    "import scipy.sparse as sps\n",
    "from scipy.stats import iqr\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "sns.set_context(rc={\"font.family\":'sans',\"font.size\":12,\"axes.titlesize\":12,\"axes.labelsize\":12})\n",
    "\n",
    "import src.utils.build_icm as build_icm\n",
    "from src.utils.data_splitter import train_test_holdout, train_test_user_holdout, train_test_row_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src/libs/RecSys_Course_2018/\") # go to parent dir\n",
    "sys.path.append(\"src/libs/RecSys_Course_2018/SequenceAware/sars_tutorial_master/\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SequenceAware.sars_tutorial_master.util.data_utils import create_seq_db_filter_top_k, sequences_to_spfm_format\n",
    "from SequenceAware.sars_tutorial_master.util.data_utils import create_seq_db_filter_top_k, sequences_to_spfm_format\n",
    "from SequenceAware.sars_tutorial_master.util.split import last_session_out_split\n",
    "from SequenceAware.sars_tutorial_master.util.metrics import precision, recall, mrr\n",
    "from SequenceAware.sars_tutorial_master.util import evaluation\n",
    "from SequenceAware.sars_tutorial_master.recommenders.MixedMarkovRecommender import MixedMarkovChainRecommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUPYTER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JUPYTER:\n",
    "    # Jupyter\n",
    "    tracks_csv_file = \"../../../data/tracks.csv\"\n",
    "    interactions_csv_file = \"../../../data/train.csv\"\n",
    "    playlist_id_csv_file = \"../../../data/target_playlists.csv\"\n",
    "    sequential_csv_file = \"../../../data/train_sequential.csv\"\n",
    "else:\n",
    "    # PyCharm\n",
    "    tracks_csv_file = \"data/tracks.csv\"\n",
    "    interactions_csv_file = \"data/train.csv\"\n",
    "    playlist_id_csv_file = \"data/target_playlists.csv\"\n",
    "    sequential_csv_file = \"data/train_sequential.csv\"\n",
    "\n",
    "tracks_df = pd.read_csv(tracks_csv_file)\n",
    "interactions_df = pd.read_csv(interactions_csv_file)\n",
    "playlist_id_df = pd.read_csv(playlist_id_csv_file)\n",
    "train_sequential_df = pd.read_csv(sequential_csv_file)\n",
    "\n",
    "userList = interactions_df[\"playlist_id\"]\n",
    "itemList = interactions_df[\"track_id\"]\n",
    "ratingList = np.ones(interactions_df.shape[0])\n",
    "targetsList = playlist_id_df[\"playlist_id\"]\n",
    "targetsListOrdered = targetsList[:5000].tolist()\n",
    "targetsListCasual = targetsList[5000:].tolist()\n",
    "\n",
    "userList_unique = pd.unique(userList)\n",
    "itemList_unique = tracks_df[\"track_id\"]\n",
    "numUsers = len(userList_unique)\n",
    "numItems = len(itemList_unique)\n",
    "numberInteractions = interactions_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM_all = sps.coo_matrix((ratingList, (userList, itemList)))\n",
    "URM_all_csr = URM_all.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemPopularity = (URM_all>0).sum(axis=0)\n",
    "itemPopularity = np.array(itemPopularity).squeeze()\n",
    "itemPopularity_unsorted = itemPopularity\n",
    "itemPopularity = np.sort(itemPopularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare ICM and URM with splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dump/dump_URM_train_rowholdout0802', 'rb') as dump_file:\n",
    "    URM_train = pickle.load(dump_file)\n",
    "with open('dump/dump_URM_test_rowholdout0802', 'rb') as dump_file:\n",
    "    URM_test = pickle.load(dump_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fitting the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try with max_order=2 or higher too, but it will take some time to complete though due to slow heristic computations\n",
    "recommender = MixedMarkovChainRecommender(URM_train, train_sequential_df, targetsListOrdered,\n",
    "                                          min_order=1, \n",
    "                                          max_order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 02:45:22,755 - INFO - Building Markov Chain model with k = 1\n",
      "2019-01-10 02:45:22,757 - INFO - Adding nodes\n",
      "2019-01-10 02:45:28,643 - INFO - Adding edges\n",
      "2019-01-10 03:01:26,668 - INFO - Applying skipping\n",
      "2019-01-10 03:01:31,999 - INFO - Applying clustering\n",
      "2019-01-10 03:01:32,001 - INFO - 12540 states in the graph\n",
      "2019-01-10 10:18:28,692 - INFO - Building Markov Chain model with k = 2\n",
      "2019-01-10 10:18:28,694 - INFO - Adding nodes\n",
      "2019-01-10 10:18:39,576 - INFO - Adding edges\n",
      "2019-01-10 10:18:59,258 - INFO - Applying skipping\n",
      "2019-01-10 10:19:16,165 - INFO - Applying clustering\n",
      "2019-01-10 10:19:16,186 - INFO - 817026 states in the graph\n"
     ]
    }
   ],
   "source": [
    "recommender.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_rat = recommender.compute_markov_score(targetsListOrdered)\n",
    "print(est_rat)\n",
    "est_rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = recommender.recommend(targetsListOrdered, cutoff=10) # tree is good, there must be sth wrong here\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and loading mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.saveModel(\"dump/\", \"dump_MixedMarkovChainRecommender_ord_1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_load = MixedMarkovChainRecommender(URM_train, train_sequential_df, targetsListOrdered,\n",
    "                                          min_order=1, \n",
    "                                          max_order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MixedMarkovChainRecommender: Loading model from file 'dump/test_save_MixedMarkovChainRecommender_ord_1_2'\n",
      "MixedMarkovChainRecommender: Loading complete\n",
      "MarkovChainRecommender: Loading model from file 'dump/test_save_MixedMarkovChainRecommender_ord_1_2_MarkovChainRecommender_order_1'\n",
      "MarkovChainRecommender: Loading complete\n",
      "MarkovChainRecommender: Loading graph model from file 'dump/test_save_MixedMarkovChainRecommender_ord_1_2_MarkovChainRecommender_order_1_G'\n",
      "MarkovChainRecommender: Loading of graph model complete\n",
      "MarkovChainRecommender: Loading model from file 'dump/test_save_MixedMarkovChainRecommender_ord_1_2_MarkovChainRecommender_order_2'\n",
      "MarkovChainRecommender: Loading complete\n",
      "MarkovChainRecommender: Loading graph model from file 'dump/test_save_MixedMarkovChainRecommender_ord_1_2_MarkovChainRecommender_order_2_G'\n",
      "MarkovChainRecommender: Loading of graph model complete\n"
     ]
    }
   ],
   "source": [
    "recommender_load.loadModel(\"dump/\", \"dump_MixedMarkovChainRecommender_ord_1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20634, 6857, 6879, 6880, 6881, 6882, 6883, 6884, 6885, 6886],\n",
       " [20634, 6853, 6875, 6876, 6877, 6878, 6879, 6880, 6881, 6882],\n",
       " [20634, 6854, 6876, 6877, 6878, 6879, 6880, 6881, 6882, 6883],\n",
       " [20634, 6851, 6873, 6874, 6875, 6876, 6877, 6878, 6879, 6880],\n",
       " [20634, 6854, 6876, 6877, 6878, 6879, 6880, 6881, 6882, 6883],\n",
       " [20634, 6852, 6874, 6875, 6876, 6877, 6878, 6879, 6880, 6881],\n",
       " [20634, 6853, 6875, 6876, 6877, 6878, 6879, 6880, 6881, 6882],\n",
       " [19926, 14796, 14732, 603, 18804, 11886, 15935, 6862, 6863, 6879],\n",
       " [20634, 6854, 6876, 6877, 6878, 6879, 6880, 6881, 6882, 6883],\n",
       " [20634, 6852, 6874, 6875, 6876, 6877, 6878, 6879, 6880, 6881]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = recommender_load.recommend(targetsListOrdered, cutoff=10) # tree is good, there must be sth wrong here\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
